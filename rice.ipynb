{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  # crawls inside folders\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count\n",
    "train_dir =r\"C:\\food\\pythonProject\\image data\\rice_leaf_diseases\\train\"\n",
    "test_dir=r\"C:\\food\\pythonProject\\image data\\rice_leaf_diseases\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Classes\n",
      "1192 Train images\n"
     ]
    }
   ],
   "source": [
    " #train file image count\n",
    "train_samples =get_files(train_dir)\n",
    "#to get tags\n",
    "num_classes=len(glob.glob(train_dir+\"/*\")) \n",
    "#test file image count\n",
    "test_samples=get_files(test_dir)\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1192 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape=(256,256,3)\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,target_size=(256,256),batch_size=32)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(256,256),batch_size=32)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                       test_dir, # same directory as training data\n",
    "                       target_size=(256,256),\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4/4 [==============================] - 55s 14s/step - loss: 0.8320 - accuracy: 0.6953 - val_loss: 1.6821 - val_accuracy: 0.7188 - lr: 5.0000e-05\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 55s 14s/step - loss: 0.3698 - accuracy: 0.9141 - val_loss: 2.1504 - val_accuracy: 0.5000 - lr: 4.8333e-05\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.3587 - accuracy: 0.8750 - val_loss: 1.0257 - val_accuracy: 0.6562 - lr: 4.5111e-05\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.2601 - accuracy: 0.9453 - val_loss: 1.6827 - val_accuracy: 0.4375 - lr: 4.0600e-05\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1588 - accuracy: 0.9219 - val_loss: 1.8523 - val_accuracy: 0.5938 - lr: 3.5187e-05\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.1550 - accuracy: 0.9219 - val_loss: 1.2864 - val_accuracy: 0.6875 - lr: 2.9322e-05\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 40s 11s/step - loss: 0.1459 - accuracy: 0.9297 - val_loss: 1.4280 - val_accuracy: 0.8125 - lr: 2.3458e-05\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 41s 11s/step - loss: 0.1002 - accuracy: 0.9531 - val_loss: 2.9460 - val_accuracy: 0.6875 - lr: 1.7984e-05\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 40s 10s/step - loss: 0.0731 - accuracy: 0.9844 - val_loss: 1.3949 - val_accuracy: 0.7812 - lr: 1.3188e-05\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0756 - accuracy: 0.9766 - val_loss: 1.7628 - val_accuracy: 0.8125 - lr: 9.2319e-06\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.1341 - accuracy: 0.9135 - val_loss: 2.7993 - val_accuracy: 0.6875 - lr: 6.1546e-06\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 34s 8s/step - loss: 0.0718 - accuracy: 0.9904 - val_loss: 1.2515 - val_accuracy: 0.8438 - lr: 3.8979e-06\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0821 - accuracy: 0.9766 - val_loss: 1.3287 - val_accuracy: 0.6875 - lr: 2.3388e-06\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0617 - accuracy: 0.9922 - val_loss: 2.1969 - val_accuracy: 0.6250 - lr: 1.3253e-06\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0456 - accuracy: 0.9844 - val_loss: 1.8587 - val_accuracy: 0.7812 - lr: 7.0682e-07\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0839 - accuracy: 0.9609 - val_loss: 1.3023 - val_accuracy: 0.8125 - lr: 3.5341e-07\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0826 - accuracy: 0.9688 - val_loss: 2.0444 - val_accuracy: 0.8125 - lr: 1.6493e-07\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0717 - accuracy: 0.9766 - val_loss: 1.2870 - val_accuracy: 0.8750 - lr: 7.1468e-08\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0761 - accuracy: 0.9688 - val_loss: 1.9693 - val_accuracy: 0.7812 - lr: 2.8587e-08\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 39s 10s/step - loss: 0.0716 - accuracy: 0.9766 - val_loss: 2.7733 - val_accuracy: 0.6562 - lr: 1.0482e-08\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 2.1347 - val_accuracy: 0.7812 - lr: 3.4940e-09\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.0873 - accuracy: 0.9712 - val_loss: 2.6282 - val_accuracy: 0.7500 - lr: 1.0482e-09\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.1046 - accuracy: 0.9766 - val_loss: 1.8257 - val_accuracy: 0.7500 - lr: 2.7952e-10\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0675 - accuracy: 0.9844 - val_loss: 2.1949 - val_accuracy: 0.7500 - lr: 6.5221e-11\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0777 - accuracy: 0.9766 - val_loss: 1.1952 - val_accuracy: 0.8750 - lr: 1.3044e-11\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0600 - accuracy: 0.9844 - val_loss: 2.3227 - val_accuracy: 0.7500 - lr: 2.1740e-12\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0846 - accuracy: 0.9844 - val_loss: 1.7694 - val_accuracy: 0.7812 - lr: 2.8987e-13\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 38s 10s/step - loss: 0.0817 - accuracy: 0.9766 - val_loss: 0.6448 - val_accuracy: 0.8125 - lr: 2.8987e-14\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.0684 - accuracy: 0.9808 - val_loss: 2.0300 - val_accuracy: 0.7500 - lr: 1.9325e-15\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 33s 8s/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 1.8748 - val_accuracy: 0.7812 - lr: 6.4416e-17\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-5\n",
    "train_batch_size = 256\n",
    "eval_batch_size = 256\n",
    "num_epochs = 30\n",
    "num_classes = 4  # Replace with the actual number of classes in your dataset\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "pretrained_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers up to a specific layer\n",
    "freeze_until_layer = 'block4_conv3'\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == freeze_until_layer:\n",
    "        break\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model2 = Model(inputs=pretrained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model2.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * (1 - epoch / num_epochs)\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_generator.samples // train_batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // eval_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 56s 6s/step - loss: 2.2289 - accuracy: 0.7071\n",
      "Test Loss: 2.2289230823516846\n",
      "Test Accuracy: 0.7071428298950195\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model2.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(r\"C:\\food\\pythonProject\\rice.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
