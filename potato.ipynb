{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  # crawls inside folders\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count\n",
    "train_dir =r\"C:\\food\\pythonProject\\image data\\potato\\train\"\n",
    "test_dir=r\"C:\\food\\pythonProject\\image data\\potato\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Classes\n",
      "1721 Train images\n",
      "431 Test images\n"
     ]
    }
   ],
   "source": [
    " #train file image count\n",
    "train_samples =get_files(train_dir)\n",
    "#to get tags\n",
    "num_classes=len(glob.glob(train_dir+\"/*\")) \n",
    "#test file image count\n",
    "test_samples=get_files(test_dir)\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "print(test_samples,\"Test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1721 images belonging to 3 classes.\n",
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape=(256,256,3)\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,target_size=(256,256),batch_size=32)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(256,256),batch_size=32)\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                       test_dir, # same directory as training data\n",
    "                       target_size=(256,256),\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fully fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-05.\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 35s 4s/step - loss: 0.9464 - accuracy: 0.5391 - val_loss: 0.6287 - val_accuracy: 0.7812 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 4.9e-05.\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.7308 - accuracy: 0.6836 - val_loss: 0.5329 - val_accuracy: 0.7188 - lr: 4.9000e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 4.8e-05.\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 36s 4s/step - loss: 0.5379 - accuracy: 0.7845 - val_loss: 0.4193 - val_accuracy: 0.8438 - lr: 4.8000e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 4.7e-05.\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.4992 - accuracy: 0.8086 - val_loss: 0.3573 - val_accuracy: 0.9062 - lr: 4.7000e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 4.600000000000001e-05.\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.4384 - accuracy: 0.8555 - val_loss: 0.3878 - val_accuracy: 0.8125 - lr: 4.6000e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 4.5e-05.\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.3535 - accuracy: 0.8828 - val_loss: 0.3644 - val_accuracy: 0.8438 - lr: 4.5000e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 4.4000000000000006e-05.\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2700 - accuracy: 0.9023 - val_loss: 0.3697 - val_accuracy: 0.8438 - lr: 4.4000e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 4.3e-05.\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.2781 - accuracy: 0.8828 - val_loss: 0.2946 - val_accuracy: 0.8750 - lr: 4.3000e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 4.2e-05.\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.2617 - accuracy: 0.9141 - val_loss: 0.2248 - val_accuracy: 0.9062 - lr: 4.2000e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 4.100000000000001e-05.\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2729 - accuracy: 0.9219 - val_loss: 0.2687 - val_accuracy: 0.9375 - lr: 4.1000e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 4e-05.\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.3051 - accuracy: 0.9052 - val_loss: 0.3673 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 3.9000000000000006e-05.\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.2255 - accuracy: 0.9219 - val_loss: 0.1289 - val_accuracy: 1.0000 - lr: 3.9000e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 3.8e-05.\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2226 - accuracy: 0.9336 - val_loss: 0.1629 - val_accuracy: 0.9688 - lr: 3.8000e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 3.7e-05.\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2277 - accuracy: 0.9375 - val_loss: 0.1784 - val_accuracy: 0.9688 - lr: 3.7000e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 3.6e-05.\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1529 - accuracy: 0.9570 - val_loss: 0.0867 - val_accuracy: 1.0000 - lr: 3.6000e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 3.5e-05.\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2097 - accuracy: 0.9414 - val_loss: 0.2988 - val_accuracy: 0.9062 - lr: 3.5000e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 3.4e-05.\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 44s 6s/step - loss: 0.1770 - accuracy: 0.9453 - val_loss: 0.0870 - val_accuracy: 1.0000 - lr: 3.4000e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 3.2999999999999996e-05.\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1757 - accuracy: 0.9414 - val_loss: 0.1434 - val_accuracy: 0.9688 - lr: 3.3000e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 3.2000000000000005e-05.\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.2658 - accuracy: 0.9023 - val_loss: 0.1147 - val_accuracy: 1.0000 - lr: 3.2000e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 3.1e-05.\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1712 - accuracy: 0.9453 - val_loss: 0.1897 - val_accuracy: 0.9375 - lr: 3.1000e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 3e-05.\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1421 - accuracy: 0.9648 - val_loss: 0.1688 - val_accuracy: 0.9062 - lr: 3.0000e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 2.9000000000000004e-05.\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 43s 5s/step - loss: 0.1362 - accuracy: 0.9727 - val_loss: 0.1547 - val_accuracy: 1.0000 - lr: 2.9000e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 2.8000000000000003e-05.\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1413 - accuracy: 0.9570 - val_loss: 0.1622 - val_accuracy: 0.9375 - lr: 2.8000e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 2.7000000000000002e-05.\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 38s 5s/step - loss: 0.1880 - accuracy: 0.9353 - val_loss: 0.2596 - val_accuracy: 0.9375 - lr: 2.7000e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 2.6000000000000002e-05.\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1299 - accuracy: 0.9648 - val_loss: 0.1112 - val_accuracy: 0.9688 - lr: 2.6000e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 2.5e-05.\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1729 - accuracy: 0.9414 - val_loss: 0.1665 - val_accuracy: 0.9688 - lr: 2.5000e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 2.4e-05.\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 44s 6s/step - loss: 0.1762 - accuracy: 0.9453 - val_loss: 0.1726 - val_accuracy: 0.9375 - lr: 2.4000e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 2.3e-05.\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1212 - accuracy: 0.9609 - val_loss: 0.1616 - val_accuracy: 0.9688 - lr: 2.3000e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 2.2e-05.\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.2025 - accuracy: 0.9336 - val_loss: 0.1993 - val_accuracy: 0.9688 - lr: 2.2000e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 2.1000000000000002e-05.\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1497 - accuracy: 0.9570 - val_loss: 0.1243 - val_accuracy: 0.9688 - lr: 2.1000e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 48s 6s/step - loss: 0.1667 - accuracy: 0.9297 - val_loss: 0.1090 - val_accuracy: 0.9688 - lr: 2.0000e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 1.9e-05.\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 47s 6s/step - loss: 0.1370 - accuracy: 0.9688 - val_loss: 0.1365 - val_accuracy: 0.9062 - lr: 1.9000e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 1.8e-05.\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 46s 6s/step - loss: 0.1823 - accuracy: 0.9375 - val_loss: 0.1699 - val_accuracy: 0.9688 - lr: 1.8000e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 1.7e-05.\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 47s 6s/step - loss: 0.1349 - accuracy: 0.9531 - val_loss: 0.1532 - val_accuracy: 0.9375 - lr: 1.7000e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1.6e-05.\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 43s 5s/step - loss: 0.1338 - accuracy: 0.9609 - val_loss: 0.1153 - val_accuracy: 0.9688 - lr: 1.6000e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1.5000000000000004e-05.\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1568 - accuracy: 0.9492 - val_loss: 0.1023 - val_accuracy: 0.9688 - lr: 1.5000e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1.4000000000000001e-05.\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1689 - accuracy: 0.9492 - val_loss: 0.1924 - val_accuracy: 0.9375 - lr: 1.4000e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1.3000000000000001e-05.\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1128 - accuracy: 0.9688 - val_loss: 0.1374 - val_accuracy: 0.9688 - lr: 1.3000e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1.2e-05.\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 43s 5s/step - loss: 0.1176 - accuracy: 0.9766 - val_loss: 0.1636 - val_accuracy: 0.9375 - lr: 1.2000e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1.1e-05.\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 39s 5s/step - loss: 0.1576 - accuracy: 0.9483 - val_loss: 0.2748 - val_accuracy: 0.9375 - lr: 1.1000e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 9.999999999999997e-06.\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1517 - accuracy: 0.9648 - val_loss: 0.1361 - val_accuracy: 0.9688 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 9.000000000000004e-06.\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1639 - accuracy: 0.9453 - val_loss: 0.1659 - val_accuracy: 0.9062 - lr: 9.0000e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 8.000000000000001e-06.\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1345 - accuracy: 0.9609 - val_loss: 0.1254 - val_accuracy: 0.9688 - lr: 8.0000e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 7.000000000000001e-06.\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1317 - accuracy: 0.9531 - val_loss: 0.2024 - val_accuracy: 0.9062 - lr: 7.0000e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6e-06.\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1308 - accuracy: 0.9688 - val_loss: 0.2756 - val_accuracy: 0.9375 - lr: 6.0000e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 4.999999999999999e-06.\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 37s 5s/step - loss: 0.1379 - accuracy: 0.9612 - val_loss: 0.1803 - val_accuracy: 0.9062 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 3.999999999999998e-06.\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.1833 - val_accuracy: 0.9688 - lr: 4.0000e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 3.0000000000000026e-06.\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 41s 5s/step - loss: 0.1397 - accuracy: 0.9531 - val_loss: 0.1214 - val_accuracy: 0.9688 - lr: 3.0000e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 2.000000000000002e-06.\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 42s 5s/step - loss: 0.1555 - accuracy: 0.9453 - val_loss: 0.0818 - val_accuracy: 0.9688 - lr: 2.0000e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.000000000000001e-06.\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 40s 5s/step - loss: 0.1364 - accuracy: 0.9648 - val_loss: 0.1430 - val_accuracy: 0.9375 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 5e-5\n",
    "train_batch_size = 256\n",
    "eval_batch_size = 256\n",
    "num_epochs = 50\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "pretrained_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers in the pretrained model\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=pretrained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: learning_rate * (1 - epoch / num_epochs),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_generator.samples // train_batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // eval_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine tuned upto a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 70s 11s/step - loss: 0.9351 - accuracy: 0.5469 - val_loss: 0.7199 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 63s 11s/step - loss: 0.5086 - accuracy: 0.8646 - val_loss: 0.3229 - val_accuracy: 0.9062 - lr: 4.8333e-05\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 63s 11s/step - loss: 0.4753 - accuracy: 0.8385 - val_loss: 0.3710 - val_accuracy: 0.8750 - lr: 4.5111e-05\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3467 - accuracy: 0.8594 - val_loss: 0.3839 - val_accuracy: 0.8125 - lr: 4.0600e-05\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 62s 11s/step - loss: 0.2414 - accuracy: 0.9323 - val_loss: 0.1414 - val_accuracy: 0.9688 - lr: 3.5187e-05\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.3243 - accuracy: 0.8333 - val_loss: 0.1394 - val_accuracy: 0.9375 - lr: 2.9322e-05\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2062 - accuracy: 0.9375 - val_loss: 0.1257 - val_accuracy: 0.9688 - lr: 2.3458e-05\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1419 - accuracy: 0.9427 - val_loss: 0.1676 - val_accuracy: 0.9062 - lr: 1.7984e-05\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.2034 - accuracy: 0.9115 - val_loss: 0.2182 - val_accuracy: 0.8750 - lr: 1.3188e-05\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1591 - accuracy: 0.9583 - val_loss: 0.1738 - val_accuracy: 0.9375 - lr: 9.2319e-06\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 62s 10s/step - loss: 0.1322 - accuracy: 0.9531 - val_loss: 0.2161 - val_accuracy: 0.9375 - lr: 6.1546e-06\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.1489 - val_accuracy: 0.9375 - lr: 3.8979e-06\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 59s 10s/step - loss: 0.1052 - accuracy: 0.9635 - val_loss: 0.0884 - val_accuracy: 0.9688 - lr: 2.3388e-06\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.0931 - val_accuracy: 0.9375 - lr: 1.3253e-06\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0869 - accuracy: 0.9688 - val_loss: 0.1484 - val_accuracy: 0.9375 - lr: 7.0682e-07\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1472 - accuracy: 0.9635 - val_loss: 0.1432 - val_accuracy: 0.9688 - lr: 3.5341e-07\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.0844 - accuracy: 0.9740 - val_loss: 0.3112 - val_accuracy: 0.9062 - lr: 1.6493e-07\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1141 - accuracy: 0.9635 - val_loss: 0.1261 - val_accuracy: 0.9375 - lr: 7.1468e-08\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.0979 - accuracy: 0.9740 - val_loss: 0.0948 - val_accuracy: 0.9375 - lr: 2.8587e-08\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1460 - accuracy: 0.9271 - val_loss: 0.1185 - val_accuracy: 0.9688 - lr: 1.0482e-08\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: 0.1731 - accuracy: 0.9323 - val_loss: 0.1521 - val_accuracy: 0.9375 - lr: 3.4940e-09\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: 0.1341 - accuracy: 0.9375 - val_loss: 0.1010 - val_accuracy: 0.9688 - lr: 1.0482e-09\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 71s 12s/step - loss: 0.1070 - accuracy: 0.9583 - val_loss: 0.1977 - val_accuracy: 0.9062 - lr: 2.7952e-10\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.1146 - accuracy: 0.9531 - val_loss: 0.2226 - val_accuracy: 0.9062 - lr: 6.5221e-11\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.1450 - accuracy: 0.9479 - val_loss: 0.0862 - val_accuracy: 0.9688 - lr: 1.3044e-11\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.1292 - accuracy: 0.9427 - val_loss: 0.2204 - val_accuracy: 0.9062 - lr: 2.1740e-12\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 77s 14s/step - loss: 0.1154 - accuracy: 0.9730 - val_loss: 0.1738 - val_accuracy: 0.9375 - lr: 2.8987e-13\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.1089 - accuracy: 0.9635 - val_loss: 0.1388 - val_accuracy: 0.9375 - lr: 2.8987e-14\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: 0.1247 - accuracy: 0.9635 - val_loss: 0.1320 - val_accuracy: 0.9375 - lr: 1.9325e-15\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 76s 13s/step - loss: 0.1133 - accuracy: 0.9676 - val_loss: 0.1449 - val_accuracy: 0.9375 - lr: 6.4416e-17\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-5\n",
    "train_batch_size = 256\n",
    "eval_batch_size = 256\n",
    "num_epochs = 30\n",
    "num_classes = 3  # Replace with the actual number of classes in your dataset\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "pretrained_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers up to a specific layer\n",
    "freeze_until_layer = 'block4_conv3'\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == freeze_until_layer:\n",
    "        break\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model2 = Model(inputs=pretrained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model2.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * (1 - epoch / num_epochs)\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_generator.samples // train_batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // eval_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SGD as optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "6/6 [==============================] - 52s 9s/step - loss: nan - accuracy: 0.5000 - val_loss: nan - val_accuracy: 0.5000 - lr: 0.1000\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 59s 10s/step - loss: nan - accuracy: 0.4635 - val_loss: nan - val_accuracy: 0.6250 - lr: 1.0000\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.4583 - val_loss: nan - val_accuracy: 0.3438 - lr: 10.0000\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4583 - val_loss: nan - val_accuracy: 0.3750 - lr: 1.0000\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 65s 11s/step - loss: nan - accuracy: 0.5156 - val_loss: nan - val_accuracy: 0.4688 - lr: 0.1000\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 71s 12s/step - loss: nan - accuracy: 0.5156 - val_loss: nan - val_accuracy: 0.3750 - lr: 0.0100\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4270 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-03\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4583 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4740 - val_loss: nan - val_accuracy: 0.5312 - lr: 1.0000e-07\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 62s 10s/step - loss: nan - accuracy: 0.4323 - val_loss: nan - val_accuracy: 0.3750 - lr: 1.0000e-09\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.5052 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-11\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.4479 - val_loss: nan - val_accuracy: 0.5625 - lr: 1.0000e-13\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 59s 10s/step - loss: nan - accuracy: 0.4323 - val_loss: nan - val_accuracy: 0.3125 - lr: 1.0000e-15\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.4323 - val_loss: nan - val_accuracy: 0.6250 - lr: 1.0000e-17\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4740 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-19\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4896 - val_loss: nan - val_accuracy: 0.3750 - lr: 1.0000e-21\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 62s 10s/step - loss: nan - accuracy: 0.4635 - val_loss: nan - val_accuracy: 0.3750 - lr: 1.0000e-23\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 62s 11s/step - loss: nan - accuracy: 0.4688 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-25\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 66s 11s/step - loss: nan - accuracy: 0.4844 - val_loss: nan - val_accuracy: 0.4062 - lr: 1.0000e-27\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 71s 12s/step - loss: nan - accuracy: 0.4740 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-29\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 64s 11s/step - loss: nan - accuracy: 0.5156 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-31\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 69s 12s/step - loss: nan - accuracy: 0.4479 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-33\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 79s 13s/step - loss: nan - accuracy: 0.4844 - val_loss: nan - val_accuracy: 0.1875 - lr: 1.0000e-35\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 65s 11s/step - loss: nan - accuracy: 0.4740 - val_loss: nan - val_accuracy: 0.5312 - lr: 1.0000e-37\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 68s 11s/step - loss: nan - accuracy: 0.4896 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.0000e-39\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 64s 11s/step - loss: nan - accuracy: 0.4323 - val_loss: nan - val_accuracy: 0.5312 - lr: 9.9997e-42\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.4479 - val_loss: nan - val_accuracy: 0.5000 - lr: 9.9492e-44\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.4740 - val_loss: nan - val_accuracy: 0.4688 - lr: 1.4013e-45\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 61s 10s/step - loss: nan - accuracy: 0.4219 - val_loss: nan - val_accuracy: 0.6250 - lr: 0.0000e+00\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 60s 10s/step - loss: nan - accuracy: 0.3958 - val_loss: nan - val_accuracy: 0.5312 - lr: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define hyperparameters\n",
    "initial_learning_rate = 0.01\n",
    "train_batch_size = 256\n",
    "eval_batch_size = 256\n",
    "num_epochs = 30\n",
    "num_classes = 3  # Replace with the actual number of classes in your dataset\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr * 10  # Increase learning rate by 10x for the first 3 epochs\n",
    "    elif epoch < 7:\n",
    "        return lr * 0.1  # Decrease learning rate by 10x for the next 4 epochs\n",
    "    else:\n",
    "        return lr * 0.01  # Decrease learning rate by 100x for the remaining epochs\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "pretrained_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers up to a specific layer\n",
    "freeze_until_layer = 'block4_conv3'\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == freeze_until_layer:\n",
    "        break\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model2 = Model(inputs=pretrained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=initial_learning_rate)\n",
    "model2.compile(optimizer=optimizer,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_generator.samples // train_batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // eval_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 63s 4s/step - loss: 0.1302 - accuracy: 0.9490\n",
      "Test Loss: 0.13022984564304352\n",
      "Test Accuracy: 0.9489558935165405\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model2.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    \n",
    "    if not isinstance(target_size, tuple):\n",
    "        raise ValueError(\"target_size must be a tuple of two integers (height, width)\")\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 123ms/step\n",
      "[[nan nan nan]]\n",
      "0\n",
      "Predicted Class Label: Potato___Early_blight\n"
     ]
    }
   ],
   "source": [
    "preprocessed_img = preprocess_image(img_path, target_size=(224, 224))\n",
    "\n",
    "# Make predictions\n",
    "predictions = model2.predict(preprocessed_img)\n",
    "print(predictions)\n",
    "# Get the predicted class index\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "print(predicted_class_index)\n",
    "# Get the class label associated with the predicted index\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(\"Predicted Class Label:\", predicted_class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"pototo_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
