{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from keras.layers import Convolution2D,Dense,MaxPool2D,Activation,Dropout,Flatten\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  count=0\n",
    "  # crawls inside folders\n",
    "  for current_path,dirs,files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      count+= len(glob.glob(os.path.join(current_path,dr+\"/*\")))\n",
    "  return count\n",
    "train_dir =r\"C:\\food\\pythonProject\\image data\\corn\\train\"\n",
    "test_dir=r\"C:\\food\\pythonProject\\image data\\corn\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Classes\n",
      "3080 Train images\n",
      "772 Test images\n"
     ]
    }
   ],
   "source": [
    " #train file image count\n",
    "train_samples =get_files(train_dir)\n",
    "#to get tags\n",
    "num_classes=len(glob.glob(train_dir+\"/*\")) \n",
    "#test file image count\n",
    "test_samples=get_files(test_dir)\n",
    "print(num_classes,\"Classes\")\n",
    "print(train_samples,\"Train images\")\n",
    "print(test_samples,\"Test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3080 images belonging to 4 classes.\n",
      "Found 772 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape=(256,256,3)\n",
    "train_generator =train_datagen.flow_from_directory(train_dir,target_size=(256,256),batch_size=32)\n",
    "test_generator=test_datagen.flow_from_directory(test_dir,shuffle=True,target_size=(256,256),batch_size=32)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 772 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "                       test_dir, # same directory as training data\n",
    "                       target_size=(256, 256),\n",
    "                       batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5e-05.\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 163s 13s/step - loss: 0.8162 - accuracy: 0.6694 - val_loss: 0.4924 - val_accuracy: 0.8333 - lr: 5.0000e-05\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 4.8333333333333334e-05.\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 155s 13s/step - loss: 0.3386 - accuracy: 0.8750 - val_loss: 0.2194 - val_accuracy: 0.8750 - lr: 4.8333e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 4.666666666666667e-05.\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.2184 - accuracy: 0.8984 - val_loss: 0.1997 - val_accuracy: 0.8958 - lr: 4.6667e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 4.5e-05.\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 128s 10s/step - loss: 0.1964 - accuracy: 0.9193 - val_loss: 0.1941 - val_accuracy: 0.9062 - lr: 4.5000e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 4.3333333333333334e-05.\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 151s 13s/step - loss: 0.2178 - accuracy: 0.8984 - val_loss: 0.2180 - val_accuracy: 0.8958 - lr: 4.3333e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 4.166666666666667e-05.\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 150s 12s/step - loss: 0.1705 - accuracy: 0.9375 - val_loss: 0.1167 - val_accuracy: 0.9688 - lr: 4.1667e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 4e-05.\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 346s 31s/step - loss: 0.1545 - accuracy: 0.9401 - val_loss: 0.0712 - val_accuracy: 0.9896 - lr: 4.0000e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 3.8333333333333334e-05.\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 119s 10s/step - loss: 0.1500 - accuracy: 0.9323 - val_loss: 0.2122 - val_accuracy: 0.9375 - lr: 3.8333e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 3.666666666666667e-05.\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 140s 12s/step - loss: 0.1035 - accuracy: 0.9479 - val_loss: 0.1711 - val_accuracy: 0.9167 - lr: 3.6667e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 3.5e-05.\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 138s 12s/step - loss: 0.1300 - accuracy: 0.9427 - val_loss: 0.1651 - val_accuracy: 0.9167 - lr: 3.5000e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 3.333333333333334e-05.\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 118s 10s/step - loss: 0.1537 - accuracy: 0.9444 - val_loss: 0.1276 - val_accuracy: 0.9688 - lr: 3.3333e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 3.1666666666666666e-05.\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 126s 11s/step - loss: 0.0913 - accuracy: 0.9661 - val_loss: 0.0832 - val_accuracy: 0.9688 - lr: 3.1667e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 3e-05.\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 127s 11s/step - loss: 0.0981 - accuracy: 0.9661 - val_loss: 0.0641 - val_accuracy: 0.9688 - lr: 3.0000e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.8333333333333335e-05.\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 134s 11s/step - loss: 0.1049 - accuracy: 0.9583 - val_loss: 0.2323 - val_accuracy: 0.8958 - lr: 2.8333e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 2.6666666666666667e-05.\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 131s 11s/step - loss: 0.1338 - accuracy: 0.9609 - val_loss: 0.1731 - val_accuracy: 0.9271 - lr: 2.6667e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 2.5e-05.\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 128s 11s/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.1110 - val_accuracy: 0.9479 - lr: 2.5000e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 2.3333333333333336e-05.\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 128s 11s/step - loss: 0.0862 - accuracy: 0.9661 - val_loss: 0.0977 - val_accuracy: 0.9792 - lr: 2.3333e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 2.1666666666666667e-05.\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 129s 11s/step - loss: 0.0517 - accuracy: 0.9818 - val_loss: 0.1090 - val_accuracy: 0.9688 - lr: 2.1667e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 2e-05.\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 127s 11s/step - loss: 0.0613 - accuracy: 0.9635 - val_loss: 0.0972 - val_accuracy: 0.9792 - lr: 2.0000e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 1.8333333333333336e-05.\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 120s 10s/step - loss: 0.1097 - accuracy: 0.9639 - val_loss: 0.1249 - val_accuracy: 0.9688 - lr: 1.8333e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 1.666666666666667e-05.\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0600 - accuracy: 0.9766 - val_loss: 0.1397 - val_accuracy: 0.9583 - lr: 1.6667e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 1.5000000000000004e-05.\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 116s 10s/step - loss: 0.0551 - accuracy: 0.9922 - val_loss: 0.0837 - val_accuracy: 0.9479 - lr: 1.5000e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 1.3333333333333337e-05.\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0843 - accuracy: 0.9714 - val_loss: 0.1319 - val_accuracy: 0.9688 - lr: 1.3333e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 1.1666666666666665e-05.\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9896 - lr: 1.1667e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 9.999999999999997e-06.\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0559 - accuracy: 0.9714 - val_loss: 0.0169 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.333333333333332e-06.\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0475 - accuracy: 0.9818 - val_loss: 0.0556 - val_accuracy: 0.9792 - lr: 8.3333e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 6.666666666666666e-06.\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 116s 10s/step - loss: 0.0443 - accuracy: 0.9870 - val_loss: 0.1334 - val_accuracy: 0.9792 - lr: 6.6667e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 4.999999999999999e-06.\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 114s 10s/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.1296 - val_accuracy: 0.9792 - lr: 5.0000e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 3.333333333333333e-06.\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 114s 10s/step - loss: 0.0522 - accuracy: 0.9870 - val_loss: 0.1383 - val_accuracy: 0.9583 - lr: 3.3333e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 1.6666666666666665e-06.\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0351 - accuracy: 0.9818 - val_loss: 0.1136 - val_accuracy: 0.9583 - lr: 1.6667e-06\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 5e-5\n",
    "train_batch_size = 256\n",
    "eval_batch_size = 256\n",
    "num_epochs = 30\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "pretrained_model = VGG16(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3)\n",
    ")\n",
    "\n",
    "# Freeze all layers in the pretrained model\n",
    "freeze_until_layer = 'block4_conv3'\n",
    "for layer in pretrained_model.layers:\n",
    "    if layer.name == freeze_until_layer:\n",
    "        break\n",
    "    layer.trainable = False #weights of this layer will not be updated during training\n",
    "\n",
    "# Add custom classification head\n",
    "x = Flatten()(pretrained_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=pretrained_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: learning_rate * (1 - epoch / num_epochs),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=train_generator.samples // train_batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // eval_batch_size,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 134s 5s/step - loss: 0.0691 - accuracy: 0.9754\n",
      "Test Loss: 0.06911176443099976\n",
      "Test Accuracy: 0.9753885865211487\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"corn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
